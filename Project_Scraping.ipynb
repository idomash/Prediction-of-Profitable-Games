{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports used for the code\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of genres, the scraping goes genre by genre, which is faster then extracting the genre for each game.\n",
    "list_of_genres = [\n",
    "    'Music',\n",
    "    'Action-Adventure',\n",
    "    'Adventure',\n",
    "    'Education',\n",
    "    'Fighting',\n",
    "    'Misc',\n",
    "    'MMO',\n",
    "    'Party',\n",
    "    'Platform',\n",
    "    'Puzzle',\n",
    "    'Racing',\n",
    "    'Shooter',\n",
    "    'Sandbox',\n",
    "    'Sports',\n",
    "    'Strategy',\n",
    "    'Simulation',\n",
    "    'Role-Playing',\n",
    "    'Action'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, json_name):\n",
    "    \"\"\"\n",
    "    This function handles the update of the databse json file.\n",
    "    gets:\n",
    "        data - the data which will be added to the json file\n",
    "        json_name - the name of the file to which the data will be saved.\n",
    "        \n",
    "        returns the len of the database, for viewing the progress of the script.\n",
    "    \"\"\"\n",
    "    json_data = []\n",
    "    # Loading file and extracting data\n",
    "    with open(json_name, 'r') as data_json:\n",
    "        json_data = json.load(data_json)\n",
    "    # Appending to the existing data\n",
    "    json_data.append(data)\n",
    "    # Writing to a file\n",
    "    with open(json_name, 'w') as new_update:\n",
    "        json.dump(json_data, new_update, indent=4)\n",
    "    return len(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(genre, page_n):\n",
    "    \n",
    "    \"\"\" This function will try to load the page.\n",
    "    if the page loads, it will return the HTML object\n",
    "    else - will retry.\n",
    "    gets: \n",
    "        genre - the genre which we scrape\n",
    "        page_n - the page number\n",
    "        (Both of these are used to format the link below).\n",
    "    returns:\n",
    "        when we get a good response, we return the content of the HTML \"\"\"\n",
    "    \n",
    "    url = f\"https://www.vgchartz.com/games/games.php?page={page_n}&results=200 \\\n",
    "&genre={genre}&order=Sales&ownership=Both&direction=DESC&showtotalsales= \\\n",
    "1&shownasales=1&showpalsales=1&showjapansales=1&showothersales=1&showpublisher \\\n",
    "=0&showdeveloper=1&showreleasedate=1&showlastupdate=0& \\\n",
    "showvgchartzscore=0&showcriticscore=0&showuserscore=0&showshipped=1\"\n",
    "    response = req.get(url)\n",
    "    if response.status_code == 200 and \"503 Service Unavailable\" not in str(response.content):\n",
    "        print(f'{response.status_code} | Connected!')\n",
    "        return response.content\n",
    "    else:\n",
    "        print(\n",
    "            f'{response.status_code} - Could not connect...Reconnecting in 15 seconds...')\n",
    "        t.sleep(15)\n",
    "        return load_page(genre, page_n)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_items(genre, html_object):\n",
    "    \n",
    "\"\"\"\" The function below is responsible for extracting the content of the webpage obtained from the preceding function.\n",
    "Once all the games on the page have been scraped, the data is sent to a saving function for storage.\n",
    "The function takes the following inputs:\n",
    "\n",
    "Genre: Data to be included in the JSON file.\n",
    "HTML_object: The HTML content obtained from the aforementioned function.\n",
    "\n",
    "The function returns an error if the number of results on a page is less than 5.\n",
    "This threshold accounts for the header and a few irrelevant div elements on the page.\n",
    "If there are fewer than 5 items on a page, it indicates that the page contains no relevant\n",
    "data for the given genre, signifying the completion of processing for that genre. \"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        amount = 0\n",
    "        games_from_page = []\n",
    "        soup = bs(html_object, \"html.parser\")\n",
    "        table_of_games = soup.find('div', id='generalBody').find_all('tr')\n",
    "        if len(table_of_games) > 5:\n",
    "            del table_of_games[:3]\n",
    "            del table_of_games[-1]\n",
    "            for game in table_of_games:\n",
    "                row = game.find_all('td')\n",
    "                game_record = {'name': row[2].text,\n",
    "                               'developer': row[4].text,\n",
    "                               'platform': row[3].find('img')['alt'],\n",
    "                               'genre': genre,\n",
    "                               'total_shipments': row[5].text,\n",
    "                               'total_sales': row[6].text,\n",
    "                               'na_sales': row[7].text,\n",
    "                               'pal_sales': row[8].text,\n",
    "                               'japan_sales': row[9].text,\n",
    "                               'other_sales': row[10].text,\n",
    "                               'release': row[11].text\n",
    "                               }\n",
    "                amount = save_data(game_record, \"database.json\")\n",
    "            print(f'Collected: {amount}')\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the script is done, we can save the data using this function:\n",
    "def convert_from_json_to_csv(json_file, output_name):\n",
    "    json_data = pd.read_json(json_file)\n",
    "    json_data.to_csv(f\"{output_name}.csv\")\n",
    "    time.sleep(3)\n",
    "    read_csv = pd.read_csv(f\"{output_name}.csv\")\n",
    "    read_csv.dropna(thresh=2, axis=0)\n",
    "    read_csv.to_csv(f'{output_name}_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 | Connected!\n"
     ]
    }
   ],
   "source": [
    "# Main code, runs per each genre, and activates the code parts on each data item.\n",
    "data = []\n",
    "counter = 0\n",
    "games_counter = 0\n",
    "for genre in list_of_genres:\n",
    "    for page in range(45):\n",
    "        counter += 1\n",
    "        data = load_page(genre, page)\n",
    "        status = extract_items(genre, data)\n",
    "        if not status:\n",
    "            break\n",
    "        else:\n",
    "            games_counter += 200\n",
    "            print(\n",
    "                f'TOTAL: {counter}/{14*len(list_of_genres)}/ Genre:{genre}')\n",
    "convert_from_json_to_csv('database.json','database.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
